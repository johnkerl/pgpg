# Generated by lexgen_code.py from lexgen JSON tables. Do not edit.
from __future__ import annotations

from typing import Optional

from runtime.token import Token, Location, new_eof_token, new_error_token, new_token


START_STATE = 0

TRANSITIONS: dict[int, list[tuple[int, int, int]]] = {

    0: [

        (9, 9, 1),

        (10, 10, 2),

        (13, 13, 3),

        (32, 32, 4),

        (37, 37, 5),

        (40, 40, 6),

        (41, 41, 7),

        (42, 42, 8),

        (43, 43, 9),

        (45, 45, 10),

        (47, 47, 11),

        (48, 48, 12),

        (49, 49, 13),

        (50, 50, 14),

        (51, 51, 15),

        (52, 52, 16),

        (53, 53, 17),

        (54, 54, 18),

        (55, 55, 19),

        (56, 56, 20),

        (57, 57, 21),

    ],

    8: [

        (42, 42, 22),

    ],

    12: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    13: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    14: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    15: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    16: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    17: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    18: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    19: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    20: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    21: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    23: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    24: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    25: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    26: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    27: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    28: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    29: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    30: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    31: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

    32: [

        (48, 48, 23),

        (49, 49, 24),

        (50, 50, 25),

        (51, 51, 26),

        (52, 52, 27),

        (53, 53, 28),

        (54, 54, 29),

        (55, 55, 30),

        (56, 56, 31),

        (57, 57, 32),

    ],

}

ACTIONS: dict[int, str] = {

    1: '!whitespace',

    2: '!whitespace',

    3: '!whitespace',

    4: '!whitespace',

    5: 'modulo',

    6: 'lparen',

    7: 'rparen',

    8: 'times',

    9: 'plus',

    10: 'minus',

    11: 'divide',

    12: 'int_literal',

    13: 'int_literal',

    14: 'int_literal',

    15: 'int_literal',

    16: 'int_literal',

    17: 'int_literal',

    18: 'int_literal',

    19: 'int_literal',

    20: 'int_literal',

    21: 'int_literal',

    22: 'exponentiation',

    23: 'int_literal',

    24: 'int_literal',

    25: 'int_literal',

    26: 'int_literal',

    27: 'int_literal',

    28: 'int_literal',

    29: 'int_literal',

    30: 'int_literal',

    31: 'int_literal',

    32: 'int_literal',

}


def _lookup_transition(state: int, r: int) -> Optional[int]:
    ranges = TRANSITIONS.get(state, [])
    for from_, to_, next_ in ranges:
        if r < from_:
            return None
        if from_ <= r <= to_:
            return next_
    return None


def _is_ignored_token(token_type: str) -> bool:
    return token_type.startswith("!")


class pgpg_PEMDASLexer:
    """Generated lexer implementing AbstractLexer protocol."""

    def __init__(self, input_text: str) -> None:
        self._input = input_text
        self._length = len(input_text)
        self._index = 0
        self._line = 1
        self._column = 1

    def scan(self) -> Optional[Token]:
        while True:
            if self._index >= self._length:
                return new_eof_token(Location(line=self._line, column=self._column, byte_offset=self._index))

            start_line, start_col = self._line, self._column
            start_index = self._index
            state = START_STATE
            last_accept_state: Optional[int] = None
            last_accept_index = self._index
            last_accept_line, last_accept_col = self._line, self._column

            while self._index < self._length:
                r = ord(self._input[self._index])
                next_state = _lookup_transition(state, r)
                if next_state is None:
                    break
                self._index += 1
                if self._input[self._index - 1] == "\n":
                    self._line += 1
                    self._column = 1
                else:
                    self._column += 1
                state = next_state
                if state in ACTIONS:
                    last_accept_state = state
                    last_accept_index = self._index
                    last_accept_line, last_accept_col = self._line, self._column

            if last_accept_state is None:
                r = ord(self._input[self._index]) if self._index < self._length else 0
                return new_error_token(
                    f"lexer: unrecognized input {chr(r)!r}",
                    Location(line=self._line, column=self._column, byte_offset=self._index),
                )

            lexeme = self._input[start_index:last_accept_index]
            self._index = last_accept_index
            self._line, self._column = last_accept_line, last_accept_col
            token_type = ACTIONS[last_accept_state]

            if _is_ignored_token(token_type):
                continue

            return new_token(lexeme, token_type, Location(line=start_line, column=start_col, byte_offset=start_index))
